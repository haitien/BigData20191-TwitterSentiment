{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# A Spark Session is how we interact with Spark SQL to create Dataframes\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# PySpark function for replacing characters using a regex. We'll use this to remove newline characters.\n",
    "from pyspark.sql.functions import regexp_replace, col\n",
    "\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, TimestampType\n",
    "\n",
    "# This will help catch some PySpark errors\n",
    "from py4j.protocol import Py4JJavaError\n",
    "\n",
    "# Create a SparkSession under the name \"twitter-sentiment\". Viewable via the Spark UI\n",
    "spark = SparkSession.builder.appName(\"twitter-sentiment\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/home/haitien/Desktop/TwitterSentimentAnalysis_BigData20191/data/training.1600000.processed.noemoticon.csv\"\n",
    "TEST_DATA_PATH = \"/home/haitien/Desktop/TwitterSentimentAnalysis_BigData20191/data/testdata.manual.2009.06.14.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo schema để mô tả các trường của dữ liệu\n",
    "\n",
    "fields = [StructField(\"label\", IntegerType(), True),\n",
    "          StructField(\"tweet_id\", StringType(), True),\n",
    "          StructField(\"date\", TimestampType(), True),\n",
    "          StructField(\"query_string\", StringType(), True),\n",
    "          StructField(\"user\", StringType(), True),\n",
    "          StructField(\"text\", StringType(), True)]\n",
    "\n",
    "schema = StructType(fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = spark.read.format(\"csv\").schema(schema).option(\"header\", \"false\").load(TRAIN_DATA_PATH)\n",
    "df_test = spark.read.format(\"csv\").schema(schema).option(\"header\", \"false\").load(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: integer (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- query_string: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|@switchfoot http:...|    0|\n",
      "|is upset that he ...|    0|\n",
      "|@Kenichan I dived...|    0|\n",
      "|my whole body fee...|    0|\n",
      "|@nationwideclass ...|    0|\n",
      "|@Kwesidei not the...|    0|\n",
      "|         Need a hug |    0|\n",
      "|@LOLTrish hey  lo...|    0|\n",
      "|@Tatiana_K nope t...|    0|\n",
      "|@twittera que me ...|    0|\n",
      "|spring break in p...|    0|\n",
      "|I just re-pierced...|    0|\n",
      "|@caregiving I cou...|    0|\n",
      "|@octolinz16 It it...|    0|\n",
      "|@smarrison i woul...|    0|\n",
      "|@iamjazzyfizzle I...|    0|\n",
      "|Hollis' death sce...|    0|\n",
      "|about to file taxes |    0|\n",
      "|@LettyA ahh ive a...|    0|\n",
      "|@FakerPattyPattz ...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.select(['text', 'label']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|@stellargirl I lo...|    4|\n",
      "|Reading my kindle...|    4|\n",
      "|Ok, first assesme...|    4|\n",
      "|@kenburbary You'l...|    4|\n",
      "|@mikefish  Fair e...|    4|\n",
      "|@richardebaker no...|    4|\n",
      "|Fuck this economy...|    0|\n",
      "|Jquery is my new ...|    4|\n",
      "|       Loves twitter|    4|\n",
      "|how can you not l...|    4|\n",
      "|Check this video ...|    2|\n",
      "|@Karoli I firmly ...|    0|\n",
      "|House Corresponde...|    4|\n",
      "|Watchin Espn..Jus...|    4|\n",
      "|dear nike, stop w...|    0|\n",
      "|#lebron best athl...|    4|\n",
      "|I was talking to ...|    0|\n",
      "|i love lebron. ht...|    4|\n",
      "|@ludajuice Lebron...|    0|\n",
      "|@Pmillzz lebron I...|    4|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.select(['text', 'label']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number rows on train data = 1600000\n",
      "Number rows on test data = 498\n"
     ]
    }
   ],
   "source": [
    "print(\"Number rows on train data = {}\".format(df_train.count()))\n",
    "print(\"Number rows on test data = {}\".format(df_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    4|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    4|  182|\n",
      "|    2|  139|\n",
      "|    0|  177|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select('text').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim, lower\n",
    "# Emails\n",
    "emailsRegex=r'[\\w\\.-]+@[\\w\\.-]+'\n",
    "\n",
    "# Mentions\n",
    "userMentionsRegex=r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)'\n",
    "\n",
    "#Urls\n",
    "urlsRegex=r'(f|ht)(tp)(s?)(://)(.*)[.|/][^ ]+'\n",
    "\n",
    "#Numerics\n",
    "numsRegex=r\"\\b\\d+\\b\"\n",
    "\n",
    "punctuationNotEmoticonsRegex=r'(?<=\\w)[^\\s\\w](?![^\\s\\w])'\n",
    "\n",
    "\n",
    "def clean_tweet(row):\n",
    "    row = lower(row)\n",
    "    row = regexp_replace(row, \"n't\", \" not\")\n",
    "    row = regexp_replace(row, emailsRegex, \" \")\n",
    "    row = regexp_replace(row, userMentionsRegex, \" \")\n",
    "    row = regexp_replace(row, urlsRegex, \" \")\n",
    "    row = regexp_replace(row, numsRegex, \" \")\n",
    "    row = regexp_replace(row, punctuationNotEmoticonsRegex, \" \")\n",
    "    row = regexp_replace(row, r'(.)\\1{2,}', r'\\1\\1')\n",
    "    row = trim(row)\n",
    "    return row\n",
    "\n",
    "df_train_cleaned = df_train.select(['label', clean_tweet(col(\"text\")).alias(\"text\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cleaned.where(df_train_cleaned.text.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cleaned.coalesce(1).write.format(\"csv\").save(\"/home/haitien/Desktop/TwitterSentimentAnalysis_BigData20191/data/train_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.read.csv(\"/home/haitien/Desktop/TwitterSentimentAnalysis_BigData20191/data/train_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11- a11  that s a bummer11you shoulda got davi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he ca not update his facebook by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>i dived many times for the ball  managed to sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>no  it s not behaving at all  i m mad  why am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>hey  long time no see  yes.. rains a bit ,only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>_k nope they did not have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                                _c1\n",
       "0   0  11- a11  that s a bummer11you shoulda got davi...\n",
       "1   0  is upset that he ca not update his facebook by...\n",
       "2   0  i dived many times for the ball  managed to sa...\n",
       "3   0     my whole body feels itchy and like its on fire\n",
       "4   0  no  it s not behaving at all  i m mad  why am ...\n",
       "5   0                                 not the whole crew\n",
       "6   0                                         need a hug\n",
       "7   0  hey  long time no see  yes.. rains a bit ,only...\n",
       "8   0                       _k nope they did not have it\n",
       "9   0                                     que me muera ?"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11- a11  that s a bummer11you shoulda got davi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he ca not update his facebook by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 _c1\n",
       "0  11- a11  that s a bummer11you shoulda got davi...\n",
       "1  is upset that he ca not update his facebook by..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.select(['_c1']).limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.withColumnRenamed(\"_c0\", \"label\")\n",
    "df_train = df_train.withColumnRenamed(\"_c1\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    0|11- a11  that s a...|\n",
      "|    0|is upset that he ...|\n",
      "|    0|i dived many time...|\n",
      "|    0|my whole body fee...|\n",
      "|    0|no  it s not beha...|\n",
      "|    0|  not the whole crew|\n",
      "|    0|          need a hug|\n",
      "|    0|hey  long time no...|\n",
      "|    0|_k nope they did ...|\n",
      "|    0|      que me muera ?|\n",
      "|    0|spring break in p...|\n",
      "|    0|i just re pierced...|\n",
      "|    0|i could not bear ...|\n",
      "|    0|it it counts  idk...|\n",
      "|    0|i would ve been t...|\n",
      "|    0|i wish i got to w...|\n",
      "|    0|hollis  death sce...|\n",
      "|    0| about to file taxes|\n",
      "|    0|ahh ive always wa...|\n",
      "|    0|oh dear  were you...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand, when\n",
    "df_train = df_train.orderBy(rand()) \\\n",
    "                   .limit(100000) \\\n",
    "                   .withColumn(\"label\", when(col(\"label\") > 0, 1).otherwise(0)) \\\n",
    "                   .select([\"label\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.where(df_train.text.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.na.drop(subset=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(train_set, val_set) = df_train.randomSplit([0.8, 0.2], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    0|!  i missed the j...|\n",
      "|    0|!  i wish i could...|\n",
      "+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|                text|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|!  i missed the j...|[!, , i, missed, ...|(262144,[9639,139...|[0.99675013921577...|[0.73041913761973...|       0.0|\n",
      "|    0|!  i wish i could...|[!, , i, wish, i,...|(262144,[17893,20...|[6.51532457790884...|[0.99852161360287...|       0.0|\n",
      "|    0|! yay  shame abou...|[!, yay, , shame,...|(262144,[28990,59...|[2.15566982092368...|[0.89619741286587...|       0.0|\n",
      "|    0|!! i love it so m...|[!!, i, love, it,...|(262144,[2437,963...|[3.43072941531246...|[0.96865122477192...|       0.0|\n",
      "|    0|   !?  what happened|[!?, , what, happ...|(262144,[29066,81...|[2.37413192974730...|[0.91483334512949...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#  class_k probability: 1/(1 + exp(-rawPrediction_k))\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_test = df_test.filter(col(\"label\") != 2.0) \\\n",
    "                 .withColumn(\"label\", when(col(\"label\") > 0, 1.0).otherwise(0.0)) \\\n",
    "                 .select([\"label\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>[@stellargirl, i, loooooooovvvvvveee, my, kind...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-5.65563212942664, 5.65563212942664]</td>\n",
       "      <td>[0.00348556965911595, 0.9965144303408839]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>[reading, my, kindle2..., , love, it..., lee, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-10.686011238582468, 10.686011238582468]</td>\n",
       "      <td>[2.2862007167460163e-05, 0.9999771379928325]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>[ok,, first, assesment, of, the, #kindle2, ......</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[6.991131513516975, -6.991131513516975]</td>\n",
       "      <td>[0.9990808406866479, 0.0009191593133521278]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>[@kenburbary, you'll, love, your, kindle2., i'...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[2.4066804538353437, -2.4066804538353437]</td>\n",
       "      <td>[0.91733530503887, 0.08266469496113008]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>[@mikefish, , fair, enough., but, i, have, the...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-2.727225034688343, 2.727225034688343]</td>\n",
       "      <td>[0.06138585527978845, 0.9386141447202115]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "      <td>[@richardebaker, no., it, is, too, big., i'm, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3.0108893823478153, 3.0108893823478153]</td>\n",
       "      <td>[0.04693634461432041, 0.9530636553856795]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Fuck this economy. I hate aig and their non lo...</td>\n",
       "      <td>[fuck, this, economy., i, hate, aig, and, thei...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.778076832017175, -1.778076832017175]</td>\n",
       "      <td>[0.8554592311434474, 0.14454076885655268]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jquery is my new best friend.</td>\n",
       "      <td>[jquery, is, my, new, best, friend.]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-8.514938837682429, 8.514938837682429]</td>\n",
       "      <td>[0.00020041120663714295, 0.999799588793363]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Loves twitter</td>\n",
       "      <td>[loves, twitter]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-3.0673450538560987, 3.0673450538560987]</td>\n",
       "      <td>[0.044474517247150444, 0.9555254827528495]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>how can you not love Obama? he makes jokes abo...</td>\n",
       "      <td>[how, can, you, not, love, obama?, he, makes, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.9191020297840933, -0.9191020297840933]</td>\n",
       "      <td>[0.7148591027541621, 0.28514089724583785]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    1.0  @stellargirl I loooooooovvvvvveee my Kindle2. ...   \n",
       "1    1.0  Reading my kindle2...  Love it... Lee childs i...   \n",
       "2    1.0  Ok, first assesment of the #kindle2 ...it fuck...   \n",
       "3    1.0  @kenburbary You'll love your Kindle2. I've had...   \n",
       "4    1.0  @mikefish  Fair enough. But i have the Kindle2...   \n",
       "5    1.0  @richardebaker no. it is too big. I'm quite ha...   \n",
       "6    0.0  Fuck this economy. I hate aig and their non lo...   \n",
       "7    1.0                      Jquery is my new best friend.   \n",
       "8    1.0                                      Loves twitter   \n",
       "9    1.0  how can you not love Obama? he makes jokes abo...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [@stellargirl, i, loooooooovvvvvveee, my, kind...   \n",
       "1  [reading, my, kindle2..., , love, it..., lee, ...   \n",
       "2  [ok,, first, assesment, of, the, #kindle2, ......   \n",
       "3  [@kenburbary, you'll, love, your, kindle2., i'...   \n",
       "4  [@mikefish, , fair, enough., but, i, have, the...   \n",
       "5  [@richardebaker, no., it, is, too, big., i'm, ...   \n",
       "6  [fuck, this, economy., i, hate, aig, and, thei...   \n",
       "7               [jquery, is, my, new, best, friend.]   \n",
       "8                                   [loves, twitter]   \n",
       "9  [how, can, you, not, love, obama?, he, makes, ...   \n",
       "\n",
       "                                            features  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                               rawPrediction  \\\n",
       "0      [-5.65563212942664, 5.65563212942664]   \n",
       "1  [-10.686011238582468, 10.686011238582468]   \n",
       "2    [6.991131513516975, -6.991131513516975]   \n",
       "3  [2.4066804538353437, -2.4066804538353437]   \n",
       "4    [-2.727225034688343, 2.727225034688343]   \n",
       "5  [-3.0108893823478153, 3.0108893823478153]   \n",
       "6    [1.778076832017175, -1.778076832017175]   \n",
       "7    [-8.514938837682429, 8.514938837682429]   \n",
       "8  [-3.0673450538560987, 3.0673450538560987]   \n",
       "9  [0.9191020297840933, -0.9191020297840933]   \n",
       "\n",
       "                                    probability  prediction  \n",
       "0     [0.00348556965911595, 0.9965144303408839]         1.0  \n",
       "1  [2.2862007167460163e-05, 0.9999771379928325]         1.0  \n",
       "2   [0.9990808406866479, 0.0009191593133521278]         0.0  \n",
       "3       [0.91733530503887, 0.08266469496113008]         0.0  \n",
       "4     [0.06138585527978845, 0.9386141447202115]         1.0  \n",
       "5     [0.04693634461432041, 0.9530636553856795]         1.0  \n",
       "6     [0.8554592311434474, 0.14454076885655268]         0.0  \n",
       "7   [0.00020041120663714295, 0.999799588793363]         1.0  \n",
       "8    [0.044474517247150444, 0.9555254827528495]         1.0  \n",
       "9     [0.7148591027541621, 0.28514089724583785]         0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pipelineFit.transform(df_test)\n",
    "predictions.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6934873036567951"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pipelineFit.write().save(\"saved_model/model3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "model1 = PipelineModel.read().load(\"saved_model/model\")\n",
    "model2 = PipelineModel.read().load(\"saved_model/model2\")\n",
    "model3 = PipelineModel.read().load(\"saved_model/model3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model3.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Utility class for plotting ROC curve (https://stackoverflow.com/questions/52847408/pyspark-extract-roc-curve)\n",
    "class CurveMetrics(BinaryClassificationMetrics):\n",
    "    def __init__(self, *args):\n",
    "        super(CurveMetrics, self).__init__(*args)\n",
    "\n",
    "    def get_curve(self, method):\n",
    "        rdd = getattr(self._java_model, method)().toJavaRDD()\n",
    "        points = []\n",
    "        for row in rdd.collect():\n",
    "            points += [(float(row._1()), float(row._2()))]\n",
    "        return points\n",
    "\n",
    "preds = predictions.select(\"label\", \"probability\") \\\n",
    "                   .rdd.map(lambda row: (float(row[\"probability\"][1]), float(row[\"label\"])))\n",
    "roc_points = CurveMetrics(preds).get_curve(\"roc\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fig = plt.figure()\n",
    "x_val = [x[0] for x in roc_points]\n",
    "y_val = [x[1] for x in roc_points]\n",
    "plt.title(\"ROC curve on test set\")\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.plot(x_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand, when\n",
    "df_train = df_train.orderBy(rand()) \\\n",
    "                   .limit(100000) \\\n",
    "                   .withColumn(\"label\", when(col(\"label\") > 0, 1).otherwise(1)) \\\n",
    "                   .select([\"label\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.where(df_train.text.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.na.drop(subset=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, val_set) = df_train.randomSplit([0.8, 0.2], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#  class_k probability: 1/(1 + exp(-rawPrediction_k))\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.filter(col(\"label\") != 2.0) \\\n",
    "                 .withColumn(\"label\", when(col(\"label\") > 0, 1.0).otherwise(0.0)) \\\n",
    "                 .select([\"label\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipelineFit.transform(df_test)\n",
    "predictions.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit.write().save(\"saved_model/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "model1 = PipelineModel.read().load(\"saved_model/model\")\n",
    "model2 = PipelineModel.read().load(\"saved_model/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model1.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Utility class for plotting ROC curve (https://stackoverflow.com/questions/52847408/pyspark-extract-roc-curve)\n",
    "class CurveMetrics(BinaryClassificationMetrics):\n",
    "    def __init__(self, *args):\n",
    "        super(CurveMetrics, self).__init__(*args)\n",
    "\n",
    "    def get_curve(self, method):\n",
    "        rdd = getattr(self._java_model, method)().toJavaRDD()\n",
    "        points = []\n",
    "        for row in rdd.collect():\n",
    "            points += [(float(row._1()), float(row._2()))]\n",
    "        return points\n",
    "\n",
    "preds = predictions.select(\"label\", \"probability\") \\\n",
    "                   .rdd.map(lambda row: (float(row[\"probability\"][1]), float(row[\"label\"])))\n",
    "roc_points = CurveMetrics(preds).get_curve(\"roc\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fig = plt.figure()\n",
    "x_val = [x[0] for x in roc_points]\n",
    "y_val = [x[1] for x in roc_points]\n",
    "plt.title(\"ROC curve on test set\")\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.plot(x_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
