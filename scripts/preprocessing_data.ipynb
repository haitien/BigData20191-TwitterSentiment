{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# A Spark Session is how we interact with Spark SQL to create Dataframes\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# PySpark function for replacing characters using a regex. We'll use this to remove newline characters.\n",
    "from pyspark.sql.functions import regexp_replace, col\n",
    "\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, TimestampType\n",
    "\n",
    "# This will help catch some PySpark errors\n",
    "from py4j.protocol import Py4JJavaError\n",
    "\n",
    "# Create a SparkSession under the name \"reddit\". Viewable via the Spark UI\n",
    "spark = SparkSession.builder.appName(\"twitter-sentiment\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/home/haitien/Desktop/TwitterSentimentAnalysis_BigData20191/data/training.1600000.processed.noemoticon.csv\"\n",
    "TEST_DATA_PATH = \"/home/haitien/Desktop/TwitterSentimentAnalysis_BigData20191/data/testdata.manual.2009.06.14.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [StructField(\"label\", IntegerType(), True),\n",
    "          StructField(\"tweet_id\", StringType(), True),\n",
    "          StructField(\"date\", TimestampType(), True),\n",
    "          StructField(\"query_string\", StringType(), True),\n",
    "          StructField(\"user\", StringType(), True),\n",
    "          StructField(\"text\", StringType(), True)]\n",
    "schema = StructType(fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = spark.read.format(\"csv\").schema(schema).option(\"header\", \"false\").load(TRAIN_DATA_PATH)\n",
    "df_test = spark.read.format(\"csv\").schema(schema).option(\"header\", \"false\").load(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: integer (nullable = true)\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- query_string: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|@switchfoot http:...|    0|\n",
      "|is upset that he ...|    0|\n",
      "|@Kenichan I dived...|    0|\n",
      "|my whole body fee...|    0|\n",
      "|@nationwideclass ...|    0|\n",
      "|@Kwesidei not the...|    0|\n",
      "|         Need a hug |    0|\n",
      "|@LOLTrish hey  lo...|    0|\n",
      "|@Tatiana_K nope t...|    0|\n",
      "|@twittera que me ...|    0|\n",
      "|spring break in p...|    0|\n",
      "|I just re-pierced...|    0|\n",
      "|@caregiving I cou...|    0|\n",
      "|@octolinz16 It it...|    0|\n",
      "|@smarrison i woul...|    0|\n",
      "|@iamjazzyfizzle I...|    0|\n",
      "|Hollis' death sce...|    0|\n",
      "|about to file taxes |    0|\n",
      "|@LettyA ahh ive a...|    0|\n",
      "|@FakerPattyPattz ...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.select(['text', 'label']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|@stellargirl I lo...|    4|\n",
      "|Reading my kindle...|    4|\n",
      "|Ok, first assesme...|    4|\n",
      "|@kenburbary You'l...|    4|\n",
      "|@mikefish  Fair e...|    4|\n",
      "|@richardebaker no...|    4|\n",
      "|Fuck this economy...|    0|\n",
      "|Jquery is my new ...|    4|\n",
      "|       Loves twitter|    4|\n",
      "|how can you not l...|    4|\n",
      "|Check this video ...|    2|\n",
      "|@Karoli I firmly ...|    0|\n",
      "|House Corresponde...|    4|\n",
      "|Watchin Espn..Jus...|    4|\n",
      "|dear nike, stop w...|    0|\n",
      "|#lebron best athl...|    4|\n",
      "|I was talking to ...|    0|\n",
      "|i love lebron. ht...|    4|\n",
      "|@ludajuice Lebron...|    0|\n",
      "|@Pmillzz lebron I...|    4|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.select(['text', 'label']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number rows on train data = 1600000\n",
      "Number rows on test data = 498\n"
     ]
    }
   ],
   "source": [
    "print(\"Number rows on train data = {}\".format(df_train.count()))\n",
    "print(\"Number rows on test data = {}\".format(df_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    4|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    4|  182|\n",
      "|    2|  139|\n",
      "|    0|  177|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|@switchfoot http:...|\n",
      "|is upset that he ...|\n",
      "|@Kenichan I dived...|\n",
      "|my whole body fee...|\n",
      "|@nationwideclass ...|\n",
      "|@Kwesidei not the...|\n",
      "|         Need a hug |\n",
      "|@LOLTrish hey  lo...|\n",
      "|@Tatiana_K nope t...|\n",
      "|@twittera que me ...|\n",
      "|spring break in p...|\n",
      "|I just re-pierced...|\n",
      "|@caregiving I cou...|\n",
      "|@octolinz16 It it...|\n",
      "|@smarrison i woul...|\n",
      "|@iamjazzyfizzle I...|\n",
      "|Hollis' death sce...|\n",
      "|about to file taxes |\n",
      "|@LettyA ahh ive a...|\n",
      "|@FakerPattyPattz ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.select('text').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim, lower\n",
    "# Emails\n",
    "emailsRegex=r'[\\w\\.-]+@[\\w\\.-]+'\n",
    "\n",
    "# Mentions\n",
    "userMentionsRegex=r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)'\n",
    "\n",
    "#Urls\n",
    "urlsRegex=r'(f|ht)(tp)(s?)(://)(.*)[.|/][^ ]+'\n",
    "\n",
    "#Numerics\n",
    "numsRegex=r\"\\b\\d+\\b\"\n",
    "\n",
    "punctuationNotEmoticonsRegex=r'(?<=\\w)[^\\s\\w](?![^\\s\\w])'\n",
    "\n",
    "\n",
    "def clean_tweet(col):\n",
    "    col = lower(col)\n",
    "    col = regexp_replace(col, \"n't\", \" not\")\n",
    "    col = regexp_replace(col, emailsRegex, \" \")\n",
    "    col = regexp_replace(col, userMentionsRegex, \" \")\n",
    "    col = regexp_replace(col, urlsRegex, \" \")\n",
    "    col = regexp_replace(col, numsRegex, \" \")\n",
    "    col = regexp_replace(col, punctuationNotEmoticonsRegex, \" \")\n",
    "    col = regexp_replace(col, r'(.)\\1{2,}', r'\\1\\1')\n",
    "    col = trim(col)\n",
    "    return col\n",
    "\n",
    "df_train_cleaned = df_train.select(['label', clean_tweet(col(\"text\")).alias(\"text\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cleaned.where(df_train_cleaned.text.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cleaned.coalesce(1).write.format(\"csv\").save(\"/home/haitien/Desktop/TwitterSentimentAnalysis_BigData20191/data/train_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.read.csv(\"/home/haitien/Desktop/TwitterSentimentAnalysis_BigData20191/data/train_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11- a11  that s a bummer11you shoulda got davi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he ca not update his facebook by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>i dived many times for the ball  managed to sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>no  it s not behaving at all  i m mad  why am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>hey  long time no see  yes.. rains a bit ,only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>_k nope they did not have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0                                                _c1\n",
       "0   0  11- a11  that s a bummer11you shoulda got davi...\n",
       "1   0  is upset that he ca not update his facebook by...\n",
       "2   0  i dived many times for the ball  managed to sa...\n",
       "3   0     my whole body feels itchy and like its on fire\n",
       "4   0  no  it s not behaving at all  i m mad  why am ...\n",
       "5   0                                 not the whole crew\n",
       "6   0                                         need a hug\n",
       "7   0  hey  long time no see  yes.. rains a bit ,only...\n",
       "8   0                       _k nope they did not have it\n",
       "9   0                                     que me muera ?"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.withColumnRenamed(\"_c0\", \"label\")\n",
    "df_train = df_train.withColumnRenamed(\"_c1\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand, when\n",
    "df_train = df_train.orderBy(rand()) \\\n",
    "                   .limit(100000) \\\n",
    "                   .withColumn(\"label\", when(col(\"label\") > 0, 1).otherwise(1)) \\\n",
    "                   .select([\"label\", \"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train.where(df_train.text.isNull()).count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train = df_train.na.drop(subset=[\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(train_set, val_set) = df_train.randomSplit([0.8, 0.2], seed = 2000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#  class_k probability: 1/(1 + exp(-rawPrediction_k))\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = df_test.filter(col(\"label\") != 2.0) \\\n",
    "                 .withColumn(\"label\", when(col(\"label\") > 0, 1.0).otherwise(0.0)) \\\n",
    "                 .select([\"label\", \"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = pipelineFit.transform(df_test)\n",
    "predictions.limit(10).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipelineFit.write().save(\"saved_model/model2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "model1 = PipelineModel.read().load(\"saved_model/model\")\n",
    "model2 = PipelineModel.read().load(\"saved_model/model2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = model1.transform(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Utility class for plotting ROC curve (https://stackoverflow.com/questions/52847408/pyspark-extract-roc-curve)\n",
    "class CurveMetrics(BinaryClassificationMetrics):\n",
    "    def __init__(self, *args):\n",
    "        super(CurveMetrics, self).__init__(*args)\n",
    "\n",
    "    def get_curve(self, method):\n",
    "        rdd = getattr(self._java_model, method)().toJavaRDD()\n",
    "        points = []\n",
    "        for row in rdd.collect():\n",
    "            points += [(float(row._1()), float(row._2()))]\n",
    "        return points\n",
    "\n",
    "preds = predictions.select(\"label\", \"probability\") \\\n",
    "                   .rdd.map(lambda row: (float(row[\"probability\"][1]), float(row[\"label\"])))\n",
    "roc_points = CurveMetrics(preds).get_curve(\"roc\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fig = plt.figure()\n",
    "x_val = [x[0] for x in roc_points]\n",
    "y_val = [x[1] for x in roc_points]\n",
    "plt.title(\"ROC curve on test set\")\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.plot(x_val, y_val)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    0|11- a11  that s a...|\n",
      "|    0|is upset that he ...|\n",
      "|    0|i dived many time...|\n",
      "|    0|my whole body fee...|\n",
      "|    0|no  it s not beha...|\n",
      "|    0|  not the whole crew|\n",
      "|    0|          need a hug|\n",
      "|    0|hey  long time no...|\n",
      "|    0|_k nope they did ...|\n",
      "|    0|      que me muera ?|\n",
      "|    0|spring break in p...|\n",
      "|    0|i just re pierced...|\n",
      "|    0|i could not bear ...|\n",
      "|    0|it it counts  idk...|\n",
      "|    0|i would ve been t...|\n",
      "|    0|i wish i got to w...|\n",
      "|    0|hollis  death sce...|\n",
      "|    0| about to file taxes|\n",
      "|    0|ahh ive always wa...|\n",
      "|    0|oh dear  were you...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand, when\n",
    "df_train = df_train.orderBy(rand()) \\\n",
    "                   .limit(100000) \\\n",
    "                   .withColumn(\"label\", when(col(\"label\") > 0, 1).otherwise(1)) \\\n",
    "                   .select([\"label\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.where(df_train.text.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.na.drop(subset=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, val_set) = df_train.randomSplit([0.8, 0.2], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    1|!  pairs of conve...|\n",
      "|    1|!  unfortunately ...|\n",
      "|    1|!  yoopers spell ...|\n",
      "|    1|! do not know how...|\n",
      "|    1|               ! hey|\n",
      "|    1|! i love it  than...|\n",
      "|    1|! i was just in m...|\n",
      "|    1|!! hello  i wo no...|\n",
      "|    1|!! you rock demi!...|\n",
      "|    1|!11twitter  how t...|\n",
      "|    1|   !?  what happened|\n",
      "|    1|!identica group &...|\n",
      "|    1|#  iphone has wif...|\n",
      "|    1|#  is not fair.. ...|\n",
      "|    1|#  jimmy johnson ...|\n",
      "|    1|#  still st regis...|\n",
      "|    1|#100pushups wk2 d...|\n",
      "|    1|#10yearsofenema ....|\n",
      "|    1|#3hotwords pull m...|\n",
      "|    1|#3hotwords that i...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+-----------+----------+\n",
      "|label|                text|               words|            features|       rawPrediction|probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+-----------+----------+\n",
      "|    1|!  pairs of conve...|[!, , pairs, of, ...|(262144,[7401,963...|[-Infinity,Infinity]|  [0.0,1.0]|       1.0|\n",
      "|    1|!  unfortunately ...|[!, , unfortunate...|(262144,[28990,58...|[-Infinity,Infinity]|  [0.0,1.0]|       1.0|\n",
      "|    1|!  yoopers spell ...|[!, , yoopers, sp...|(262144,[27526,28...|[-Infinity,Infinity]|  [0.0,1.0]|       1.0|\n",
      "|    1|! do not know how...|[!, do, not, know...|(262144,[24417,28...|[-Infinity,Infinity]|  [0.0,1.0]|       1.0|\n",
      "|    1|               ! hey|            [!, hey]|(262144,[28990,66...|[-Infinity,Infinity]|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#  class_k probability: 1/(1 + exp(-rawPrediction_k))\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.filter(col(\"label\") != 2.0) \\\n",
    "                 .withColumn(\"label\", when(col(\"label\") > 0, 1.0).otherwise(0.0)) \\\n",
    "                 .select([\"label\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>words</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>[@stellargirl, i, loooooooovvvvvveee, my, kind...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-inf, inf]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>[reading, my, kindle2..., , love, it..., lee, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-inf, inf]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>[ok,, first, assesment, of, the, #kindle2, ......</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-inf, inf]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>[@kenburbary, you'll, love, your, kindle2., i'...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-inf, inf]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>[@mikefish, , fair, enough., but, i, have, the...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-inf, inf]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "      <td>[@richardebaker, no., it, is, too, big., i'm, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-inf, inf]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Fuck this economy. I hate aig and their non lo...</td>\n",
       "      <td>[fuck, this, economy., i, hate, aig, and, thei...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-inf, inf]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jquery is my new best friend.</td>\n",
       "      <td>[jquery, is, my, new, best, friend.]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-inf, inf]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Loves twitter</td>\n",
       "      <td>[loves, twitter]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-inf, inf]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>how can you not love Obama? he makes jokes abo...</td>\n",
       "      <td>[how, can, you, not, love, obama?, he, makes, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[-inf, inf]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  \\\n",
       "0    1.0  @stellargirl I loooooooovvvvvveee my Kindle2. ...   \n",
       "1    1.0  Reading my kindle2...  Love it... Lee childs i...   \n",
       "2    1.0  Ok, first assesment of the #kindle2 ...it fuck...   \n",
       "3    1.0  @kenburbary You'll love your Kindle2. I've had...   \n",
       "4    1.0  @mikefish  Fair enough. But i have the Kindle2...   \n",
       "5    1.0  @richardebaker no. it is too big. I'm quite ha...   \n",
       "6    0.0  Fuck this economy. I hate aig and their non lo...   \n",
       "7    1.0                      Jquery is my new best friend.   \n",
       "8    1.0                                      Loves twitter   \n",
       "9    1.0  how can you not love Obama? he makes jokes abo...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [@stellargirl, i, loooooooovvvvvveee, my, kind...   \n",
       "1  [reading, my, kindle2..., , love, it..., lee, ...   \n",
       "2  [ok,, first, assesment, of, the, #kindle2, ......   \n",
       "3  [@kenburbary, you'll, love, your, kindle2., i'...   \n",
       "4  [@mikefish, , fair, enough., but, i, have, the...   \n",
       "5  [@richardebaker, no., it, is, too, big., i'm, ...   \n",
       "6  [fuck, this, economy., i, hate, aig, and, thei...   \n",
       "7               [jquery, is, my, new, best, friend.]   \n",
       "8                                   [loves, twitter]   \n",
       "9  [how, can, you, not, love, obama?, he, makes, ...   \n",
       "\n",
       "                                            features rawPrediction  \\\n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   [-inf, inf]   \n",
       "1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   [-inf, inf]   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   [-inf, inf]   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   [-inf, inf]   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   [-inf, inf]   \n",
       "5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   [-inf, inf]   \n",
       "6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   [-inf, inf]   \n",
       "7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   [-inf, inf]   \n",
       "8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   [-inf, inf]   \n",
       "9  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   [-inf, inf]   \n",
       "\n",
       "  probability  prediction  \n",
       "0  [0.0, 1.0]         1.0  \n",
       "1  [0.0, 1.0]         1.0  \n",
       "2  [0.0, 1.0]         1.0  \n",
       "3  [0.0, 1.0]         1.0  \n",
       "4  [0.0, 1.0]         1.0  \n",
       "5  [0.0, 1.0]         1.0  \n",
       "6  [0.0, 1.0]         1.0  \n",
       "7  [0.0, 1.0]         1.0  \n",
       "8  [0.0, 1.0]         1.0  \n",
       "9  [0.0, 1.0]         1.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pipelineFit.transform(df_test)\n",
    "predictions.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit.write().save(\"saved_model/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "model1 = PipelineModel.read().load(\"saved_model/model\")\n",
    "model2 = PipelineModel.read().load(\"saved_model/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model1.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6508350406655491"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Utility class for plotting ROC curve (https://stackoverflow.com/questions/52847408/pyspark-extract-roc-curve)\n",
    "class CurveMetrics(BinaryClassificationMetrics):\n",
    "    def __init__(self, *args):\n",
    "        super(CurveMetrics, self).__init__(*args)\n",
    "\n",
    "    def get_curve(self, method):\n",
    "        rdd = getattr(self._java_model, method)().toJavaRDD()\n",
    "        points = []\n",
    "        for row in rdd.collect():\n",
    "            points += [(float(row._1()), float(row._2()))]\n",
    "        return points\n",
    "\n",
    "preds = predictions.select(\"label\", \"probability\") \\\n",
    "                   .rdd.map(lambda row: (float(row[\"probability\"][1]), float(row[\"label\"])))\n",
    "roc_points = CurveMetrics(preds).get_curve(\"roc\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fig = plt.figure()\n",
    "x_val = [x[0] for x in roc_points]\n",
    "y_val = [x[1] for x in roc_points]\n",
    "plt.title(\"ROC curve on test set\")\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.plot(x_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}